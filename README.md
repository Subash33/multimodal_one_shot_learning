Cross-Modal Few-Shot Learning
=============================

Overview
--------
Few-shot learning experiments on cross-modal vision-speech retrieval, where a given query in *one* modality is used to match an example with the most similar content from a (test) set of possible answers that are in *another modality*. This cross-modal matching is performed based on knowledge of another set of matching vision-speech examples (known as an acquisition set), where only one or a few matching examples are available per class.
